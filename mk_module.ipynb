{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./module/preprocessing1st.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./module/preprocessing1st.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score, StratifiedKFold ,GridSearchCV)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cates = {\n",
    "    'education' : ['Less than high school','High school','University degree','Graduate degree'],\n",
    "    'urban' : ['Rural','Suburban','Urban'],\n",
    "    'gender' : ['Male','Female','Other'],\n",
    "    'engnat' : ['Yes','No'],\n",
    "    'hand' : ['Right','Left','Both'],\n",
    "    'religion' : ['Agnostic','Atheist','Buddhist','Christian(Catholic)','Christian(Mormon)','Christian(Protestant)','Christian(othrer)','Hindu','Jewish','Muslim','Sikh','Other'],\n",
    "    'orientation' : ['Heterosexual','Bisexual','Homosexual','Asexual','Other'],\n",
    "    'race' : ['Asian','Arab','Black','Indigenous Australian','Native American','White','Other'],\n",
    "    'voted' : ['1', '0'],\n",
    "    'married' : ['Never married','Currently married','Previously married'],\n",
    "}\n",
    "\n",
    "\n",
    "class Preprocessing1st():\n",
    "    \n",
    "    def __init__(self, data, without_comma=False):\n",
    "        self.data = data\n",
    "        self.df = self.read_data(without_comma)\n",
    "        self.df_eda = self.preprocessing_eda()\n",
    "        \n",
    "    def read_data(self, without_comma):\n",
    "\n",
    "        if without_comma==False:\n",
    "            df = pd.read_csv(self.data, delimiter=\"\\t\")\n",
    "        \n",
    "        else:\n",
    "            df = pd.read_csv(self.data)\n",
    "            \n",
    "        return df\n",
    "        \n",
    "        \n",
    "    def tran_cate(self, df, cate, x, y):\n",
    "        self.df[cate] = self.df[cate].astype('str').replace(x, y)\n",
    "        return self.df[cate]\n",
    "\n",
    "    def preprocessing_eda(self):\n",
    "        # 직관적 EDA를 위해 컬럼명 수정\n",
    "        self.df.rename(columns = {\"Q1A\" : \"Q1_TP_notell_2u\", \"Q2A\" : \"Q2_TP_ppl_nd_dangun\", \"Q3A\" : \"Q3_TN_do_moral\", \"Q4A\" : \"Q4_VN_ppl_good\", \"Q5A\" : \"Q5_VP_ppl_bad\", \"Q6A\" : \"Q6_TN_hnsty_best\", \"Q7A\" : \"Q7_TN_lying_bad\", \"Q8A\" : \"Q8_VP_ppl_lazy\", \"Q9A\" : \"Q9_MN_humble_hnst\", \"Q10A\" : \"Q10_TN_hnstly_ask\", \"Q11A\" : \"Q11_VN_leader_clean\", \"Q12A\" : \"Q12_TP_trust_trouble\", \"Q13A\" : \"Q13_VP_ppl_criminal\", \"Q14A\" : \"Q14_VN_ppl_brave\", \"Q15A\" : \"Q15_TP_abu_good\", \"Q16A\" : \"Q16_TN_ppl_good\", \"Q17A\" : \"Q17_VN_ppl_notbad\", \"Q18A\" : \"Q18_VP_komsu_better\", \"Q19A\" : \"Q19_MP_anrocksa_ok\", \"Q20A\" : \"Q20_VP_money_good\",\n",
    "                     \"Q1E\" : \"Q1E_notell_2u\", \"Q2E\" : \"Q2E_ppl_nd_dangun\", \"Q3E\" : \"Q3E_do_moral\", \"Q4E\" : \"Q4E_ppl_good\", \"Q5E\" : \"Q5E_ppl_bad\", \"Q6E\" : \"Q6E_hnsty_best\", \"Q7E\" : \"Q7E_lying_bad\", \"Q8E\" : \"Q8E_ppl_lazy\", \"Q9E\" : \"Q9E_humble_hnst\", \"Q10E\" : \"Q10E_hnstly_ask\", \"Q11E\" : \"Q11E_leader_clean\", \"Q12E\" : \"Q12E_trust_trouble\", \"Q13E\" : \"Q13E_ppl_criminal\", \"Q14E\" : \"Q14E_ppl_brave\", \"Q15E\" : \"Q15E_abu_good\", \"Q16E\" : \"Q16E_ppl_good\", \"Q17E\" : \"Q17E_ppl_notbad\", \"Q18E\" : \"Q18E_komsu_better\", \"Q19E\" : \"Q19E_anrocksa_ok\", \"Q20E\" : \"Q20E_money_good\",\n",
    "                     \"TIPI1\":\"TYP_out\", \"TIPI2\":\"TYP_fight\", \"TIPI3\":\"TYP_depnd\", \"TIPI4\":\"TYP_anx\", \"TIPI5\":\"TYP_try\", \"TIPI6\":\"TYP_quiet\", \"TIPI7\":\"TYP_warm\", \"TIPI8\":\"TYP_disorg\", \"TIPI9\":\"TYP_calm\", \"TIPI10\":\"TYP_stable\",\n",
    "                     \"VCL6\" : \"VCL6_F\", \"VCL9\" : \"VCL9_F\", \"VCL12\" : \"VCL12_F\"\n",
    "                    }, inplace=True)        \n",
    "        \n",
    "        # score 컬럼 추가\n",
    "        col_list = list(self.df.columns)\n",
    "        pos_col = []\n",
    "        neg_col = []\n",
    "\n",
    "        for col in col_list:\n",
    "            if \"P\" in col and \"Y\" not in col:\n",
    "                pos_col.append(col)\n",
    "            if \"N\" in col:\n",
    "                neg_col.append(col)\n",
    "\n",
    "        self.df[\"score\"] = self.df[pos_col].sum(axis=1) + self.df[neg_col].apply(lambda x: 6 -x).sum(axis=1)\n",
    "        \n",
    "        # V, T, M score 컬럼 추가 \n",
    "        v_score = []\n",
    "        t_score = []\n",
    "        m_score = []\n",
    "\n",
    "        for col in col_list:\n",
    "            if \"T\" in col:\n",
    "                t_score.append(col)\n",
    "            if \"M\" in col:\n",
    "                m_score.append(col)\n",
    "            if \"V\" in col:\n",
    "                v_score.append(col)\n",
    "        self.df[\"v_score\"] = self.df[v_score].sum(axis=1)\n",
    "        self.df[\"t_score\"] = self.df[t_score].sum(axis=1)\n",
    "        self.df[\"m_score\"] = self.df[m_score].sum(axis=1)\n",
    "        \n",
    "                \n",
    "        # 텍스트 데이터로 변환, 시간 데이터 초단위로 환산\n",
    "        vcl_col = []\n",
    "        sec_col = []\n",
    "\n",
    "        for col in col_list:\n",
    "            if \"VCL\" in col:\n",
    "                vcl_col.append(col)\n",
    "            if \"E\" in col:\n",
    "                sec_col.append(col)\n",
    "        \n",
    "        self.df[vcl_col] = self.df[vcl_col].applymap(lambda x: str(x).replace(\"1\", \"know\") if x==1 \n",
    "                                           else str(x).replace(\"0\", \"n_know\"))\n",
    "        self.df[sec_col] = self.df[sec_col].apply(lambda x: round(x*0.001))\n",
    "        \n",
    "        for x in list(cates.keys()):\n",
    "            for idx, y in enumerate(cates[x]):\n",
    "                if x == 'race':\n",
    "                    self.tran_cate(self.df, x, \"{}\".format((idx+1)*10) ,y)\n",
    "                else:    \n",
    "                    self.tran_cate(self.df, x, \"{}\".format(idx+1) ,y)\n",
    "\n",
    "        \n",
    "        # 나이 18세 이하 데이터 drop\n",
    "        df = self.df[self.df[\"age\"]>17]\n",
    "        \n",
    "        \n",
    "        # EDA용 csv 생성\n",
    "        df.to_csv(\"../MACH_data/raw_data_for_EDA.csv\", index=False)\n",
    "        \n",
    "        return df\n",
    "                    \n",
    "                    \n",
    "    def preprocessing_model(self):                \n",
    "        # major 컬럼 drop\n",
    "        self.df_eda.drop(columns = \"major\", inplace = True)\n",
    "        col_list2 = list(self.df_eda.columns)\n",
    "\n",
    "        \n",
    "        # null, 0 데이터 제거\n",
    "        self.df_eda.dropna(inplace=True)\n",
    "        zero_idx = []\n",
    "        for col in col_list2:\n",
    "            zero_idx += list((self.df_eda[(self.df_eda[col] == 0)].index))\n",
    "        zero_idx = list(set(zero_idx))\n",
    "        self.df_eda.drop(zero_idx, inplace=True)\n",
    "\n",
    "        \n",
    "        # train, test로 나누기 \n",
    "        df_X = self.df_eda.drop('voted', axis=1)\n",
    "        df_X = pd.get_dummies(df_X)\n",
    "        \n",
    "        \n",
    "        # 추가 확인된 0 데이터 제거\n",
    "        col_in_0 = [col for col in df_X.columns if '_0' in col]\n",
    "        df_X.drop(col_in_0, axis=1, inplace=True)\n",
    "        \n",
    "        df_y = self.df_eda['voted'].astype('int')\n",
    "        \n",
    "                \n",
    "        X_train, X_test, y_train, y_test=\\\n",
    "        train_test_split(df_X, df_y, test_size=0.2,\n",
    "                         random_state=13, stratify=df_y)    \n",
    "\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./module/preprocessing_nth.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./module/preprocessing_nth.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score, StratifiedKFold ,GridSearchCV)\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# N차 전처리 클래스(feature 선별, robust scaling, weight 컬럼 추가)\n",
    "class PreprocessingNth():\n",
    "    def __init__(self):\n",
    "        ada = AdaBoostClassifier()\n",
    "        gbc = GradientBoostingClassifier()\n",
    "        xgb = XGBClassifier()\n",
    "        lgbm = LGBMClassifier()\n",
    "        self.models = [ada, gbc, xgb, lgbm]\n",
    "        self.model_names = ['Ada', 'GBC', 'XGB', 'LGBM']\n",
    "        \n",
    "        \n",
    "    def feature_selection(self, *xy_train_test):\n",
    "        X_train, X_test, y_train, y_test = xy_train_test\n",
    "        \n",
    "        datas = []\n",
    "        for model in self.models:\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        # 모델 fit 이후 feature_importances_ 0인 컬럼을 선별하기 위함.\n",
    "        ada_fi = self.models[0].feature_importances_\n",
    "        gbc_fi = self.models[1].feature_importances_\n",
    "        xgb_fi = self.models[2].feature_importances_\n",
    "        lgbm_fi = self.models[3].feature_importances_\n",
    "        \n",
    "        ada_fm = pd.DataFrame(zip(X_train.columns, ada_fi))\n",
    "        ada_list1 = list(ada_fm[ada_fm[1]==0][0])\n",
    "        gbc_fm = pd.DataFrame(zip(X_train.columns, gbc_fi))\n",
    "        gbc_list1 = list(gbc_fm[gbc_fm[1]==0][0])\n",
    "        xgb_fm = pd.DataFrame(zip(X_train.columns, xgb_fi))\n",
    "        xgb_list1 = list(xgb_fm[xgb_fm[1]==0][0])\n",
    "        lgbm_fm = pd.DataFrame(zip(X_train.columns, lgbm_fi))\n",
    "        lgbm_list1 = list(lgbm_fm[lgbm_fm[1]==0][0])\n",
    "        \n",
    "        # 4가지 모델에서의 feature_importances_가 모두 0인 컬럼들의 교집합 확인. \n",
    "        ada_gbc1 = list(set(ada_list1).intersection(gbc_list1))\n",
    "        ada_gbc_xgb1 = list(set(ada_gbc1).intersection(xgb_list1))\n",
    "        ada_gbc_xgb_lgbm1 = list(set(ada_gbc_xgb1).intersection(lgbm_list1))\n",
    "        \n",
    "        # 해당 컬럼들을 제외한 X데이터를 생성\n",
    "        X_train = X_train.drop(ada_gbc_xgb_lgbm1, axis=1)\n",
    "        X_test = X_test.drop(ada_gbc_xgb_lgbm1, axis=1)\n",
    "        \n",
    "        # feature_selection 결과 데이터 저장\n",
    "        self.feature_selection_xy = X_train, X_test, y_train, y_test\n",
    "        \n",
    "        return self.feature_selection_xy\n",
    "    \n",
    "    \n",
    "\n",
    "    def scale_robust(self, *xy_train_test):\n",
    "        X_train, X_test, y_train, y_test = xy_train_test\n",
    "        \n",
    "        num_cols = []\n",
    "        for col in X_train.columns:\n",
    "            if (\"E\" in col) | (\"age\" in col) |(\"family\" in col) |(\"elapse\" in col):\n",
    "                num_cols.append(col)\n",
    "                \n",
    "        rbscale = RobustScaler().fit(X_train[num_cols])\n",
    "        X_train[num_cols] = rbscale.transform(X_train[num_cols])\n",
    "        X_test[num_cols] = rbscale.transform(X_test[num_cols])\n",
    "        \n",
    "        # scale_robust 결과 데이터 저장\n",
    "        self.scale_robust_xy = X_train, X_test, y_train, y_test\n",
    "\n",
    "        return self.scale_robust_xy\n",
    "\n",
    "       \n",
    "    def feature_addition(self, *xy_train_test, column=\"score\", voted=\"voted\",col_name=\"rate\"):\n",
    "        X_train, X_test, y_train, y_test = xy_train_test\n",
    "\n",
    "        df_tr = pd.concat([X_train, y_train], axis=1)\n",
    "        df_te = X_test\n",
    "        add_all_tr = df_tr[[voted, column]].groupby(column).count()\n",
    "        add_yes_tr = df_tr[[voted, column]].groupby(column).sum()\n",
    "        add_no_tr = add_all_tr - add_yes_tr\n",
    "        df_add_tr = round((add_yes_tr - add_no_tr)/ add_all_tr, 4)\n",
    "        df_add_tr = df_add_tr.rename(columns={voted:col_name})\n",
    "        \n",
    "        df1_tr = pd.merge(left=df_tr, right=df_add_tr, how=\"left\", right_index=True, left_on=column)\n",
    "        df1_te = pd.merge(left=df_te, right=df_add_tr, how=\"left\", right_index=True, left_on=column)\n",
    "        X_train=df1_tr.drop(voted, axis=1)\n",
    "        y_train=pd.DataFrame(df1_tr[voted])\n",
    "        X_test=df1_te.fillna(0)\n",
    "        \n",
    "        # feature_addition 결과 데이터 저장\n",
    "        self.feature_addition_xy = X_train, X_test, y_train, y_test\n",
    "\n",
    "        return self.feature_addition_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1차 전처리 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module import preprocessing1st as pre1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1 = pre1.Preprocessing1st(\"./MACH_data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = pre1.preprocessing_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nth 전처리 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "nth = PreprocessingNth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = nth.feature_selection(*xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = nth.scale_robust(*nth.feature_selection_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1_TP_notell_2u</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E_notell_2u</th>\n",
       "      <th>Q2_TP_ppl_nd_dangun</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E_ppl_nd_dangun</th>\n",
       "      <th>Q3_TN_do_moral</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E_do_moral</th>\n",
       "      <th>Q4_VN_ppl_good</th>\n",
       "      <th>...</th>\n",
       "      <th>orientation_Homosexual</th>\n",
       "      <th>race_Arab</th>\n",
       "      <th>race_Asian</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Native American</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_White</th>\n",
       "      <th>married_Currently married</th>\n",
       "      <th>married_Never married</th>\n",
       "      <th>married_Previously married</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13302</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35701</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67361</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68523</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34740</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Q1_TP_notell_2u   Q1I  Q1E_notell_2u  Q2_TP_ppl_nd_dangun   Q2I  \\\n",
       "13302              3.0   4.0       0.000000                  2.0  17.0   \n",
       "35701              2.0  20.0      -0.166667                  2.0   3.0   \n",
       "67361              5.0   9.0       1.500000                  1.0   2.0   \n",
       "68523              5.0   9.0       0.166667                  1.0  11.0   \n",
       "34740              4.0   4.0       0.000000                  2.0  17.0   \n",
       "\n",
       "       Q2E_ppl_nd_dangun  Q3_TN_do_moral   Q3I  Q3E_do_moral  Q4_VN_ppl_good  \\\n",
       "13302               -0.2             1.0   9.0     -0.166667             2.0   \n",
       "35701                0.0             4.0  19.0     -0.166667             4.0   \n",
       "67361                0.2             4.0  10.0      0.666667             1.0   \n",
       "68523                0.2             1.0  20.0      1.666667             5.0   \n",
       "34740               -0.6             3.0  16.0     -0.833333             2.0   \n",
       "\n",
       "       ...  orientation_Homosexual  race_Arab  race_Asian  race_Black  \\\n",
       "13302  ...                       0          0           0           0   \n",
       "35701  ...                       0          0           0           0   \n",
       "67361  ...                       0          0           0           0   \n",
       "68523  ...                       0          0           0           1   \n",
       "34740  ...                       0          0           0           0   \n",
       "\n",
       "       race_Native American  race_Other  race_White  \\\n",
       "13302                     0           0           1   \n",
       "35701                     0           0           1   \n",
       "67361                     0           0           1   \n",
       "68523                     0           0           0   \n",
       "34740                     0           0           1   \n",
       "\n",
       "       married_Currently married  married_Never married  \\\n",
       "13302                          0                      1   \n",
       "35701                          0                      1   \n",
       "67361                          0                      0   \n",
       "68523                          0                      1   \n",
       "34740                          0                      1   \n",
       "\n",
       "       married_Previously married  \n",
       "13302                           0  \n",
       "35701                           0  \n",
       "67361                           1  \n",
       "68523                           0  \n",
       "34740                           0  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb[0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = nth.feature_addition(*nth.feature_selection_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13302   -0.0509\n",
       "35701    0.0826\n",
       "67361    0.0305\n",
       "68523    0.0305\n",
       "34740    0.0774\n",
       "Name: rate, dtype: float64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa[0][\"rate\"].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./module/modeling_score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./module/modeling_score.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score, StratifiedKFold ,GridSearchCV)\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ada, gbc, xgb, lgbm 모델링 클래스 \n",
    "class Modeling:    \n",
    "    def __init__(self, *xy_train_test):\n",
    "        ada = AdaBoostClassifier()\n",
    "        gbc = GradientBoostingClassifier()\n",
    "        xgb = XGBClassifier()\n",
    "        lgbm = LGBMClassifier()\n",
    "        self.datas = []\n",
    "        self.models = [ada, gbc, xgb, lgbm]\n",
    "        self.model_names = ['Ada', 'GBC', 'XGB', 'LGBM']\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = xy_train_test\n",
    "        \n",
    "        \n",
    "        # 분류모델 평가지표 계산함수 (AUC, ACC를 우선순위로 사용함)\n",
    "    def get_score(self, pred):\n",
    "        acc = accuracy_score(self.y_test, pred)\n",
    "        pre = precision_score(self.y_test, pred)\n",
    "        rec = recall_score(self.y_test, pred)\n",
    "        f1 = f1_score(self.y_test, pred)\n",
    "        auc = roc_auc_score(self.y_test, pred)\n",
    "       \n",
    "        return acc, auc, pre, rec, f1\n",
    "    \n",
    "    \n",
    "    def fit_model(self, model):\n",
    "\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        y_pre_tr = model.predict(self.X_train)\n",
    "        self.y_pre_test = model.predict(self.X_test)\n",
    "        total_score = self.get_score(self.y_pre_test)\n",
    "        \n",
    "        return total_score\n",
    "\n",
    "    \n",
    "    def models_score_df(self):\n",
    "        cols_names = ['accuracy', 'AUC', 'precision', 'recall', 'f1']\n",
    "\n",
    "        for model in self.models:\n",
    "            self.datas.append(self.fit_model(model))\n",
    "\n",
    "        df = pd.DataFrame(self.datas, columns=cols_names, index=self.model_names)\n",
    "            \n",
    "        return print(df) \n",
    "    \n",
    "    \n",
    "    # 평가지표와 confusion matrix 출력 함수\n",
    "    def print_score(self):\n",
    "        datas = []\n",
    "        for model in self.models:\n",
    "            datas.append(self.fit_model(model))\n",
    "        \n",
    "            acc, auc, pre, rec, f1 = datas[0]\n",
    "            con = confusion_matrix(self.y_test, self.y_pre_test)\n",
    "            print('='*20)\n",
    "            print(model)\n",
    "            print('confusion matrix')\n",
    "            print(con)\n",
    "            print('='*20)\n",
    "\n",
    "            print('Accuracy: {0:.4f}, AUC: {1:.4f}'.format(acc, auc))\n",
    "            print('Recall: {0:.4f}, f1_score: {1:.4f}, precision: {2:.4f}'.format(rec, f1, pre))\n",
    "            print('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = Modeling(*nth.feature_addition_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "AdaBoostClassifier()\n",
      "confusion matrix\n",
      "[[3030 2549]\n",
      " [1563 4524]]\n",
      "====================\n",
      "Accuracy: 0.6475, AUC: 0.6432\n",
      "Recall: 0.7432, f1_score: 0.6875, precision: 0.6396\n",
      "====================\n",
      "====================\n",
      "GradientBoostingClassifier()\n",
      "confusion matrix\n",
      "[[3016 2563]\n",
      " [1495 4592]]\n",
      "====================\n",
      "Accuracy: 0.6475, AUC: 0.6432\n",
      "Recall: 0.7432, f1_score: 0.6875, precision: 0.6396\n",
      "====================\n",
      "====================\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "confusion matrix\n",
      "[[3212 2367]\n",
      " [1780 4307]]\n",
      "====================\n",
      "Accuracy: 0.6475, AUC: 0.6432\n",
      "Recall: 0.7432, f1_score: 0.6875, precision: 0.6396\n",
      "====================\n",
      "====================\n",
      "LGBMClassifier()\n",
      "confusion matrix\n",
      "[[3142 2437]\n",
      " [1580 4507]]\n",
      "====================\n",
      "Accuracy: 0.6475, AUC: 0.6432\n",
      "Recall: 0.7432, f1_score: 0.6875, precision: 0.6396\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "mdsc = md.print_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ada</th>\n",
       "      <td>0.647523</td>\n",
       "      <td>0.643166</td>\n",
       "      <td>0.639615</td>\n",
       "      <td>0.743223</td>\n",
       "      <td>0.687538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBC</th>\n",
       "      <td>0.652152</td>\n",
       "      <td>0.647497</td>\n",
       "      <td>0.641789</td>\n",
       "      <td>0.754395</td>\n",
       "      <td>0.693551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.644523</td>\n",
       "      <td>0.641652</td>\n",
       "      <td>0.645340</td>\n",
       "      <td>0.707574</td>\n",
       "      <td>0.675025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>0.655666</td>\n",
       "      <td>0.651807</td>\n",
       "      <td>0.649050</td>\n",
       "      <td>0.740430</td>\n",
       "      <td>0.691735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy       AUC  precision    recall        f1\n",
       "Ada   0.647523  0.643166   0.639615  0.743223  0.687538\n",
       "GBC   0.652152  0.647497   0.641789  0.754395  0.693551\n",
       "XGB   0.644523  0.641652   0.645340  0.707574  0.675025\n",
       "LGBM  0.655666  0.651807   0.649050  0.740430  0.691735"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.models_score_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./module/ml_project_result_machia_voted.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./module/ml_project_result_machia_voted.py\n",
    "\n",
    "import preprocessing1st as pre1\n",
    "import preprocessing_nth as prenth\n",
    "import modeling_score as mdsc\n",
    "\n",
    "# 1st preprocessing\n",
    "pre = pre1.Preprocessing1st(\"../MACH_data/data.csv\")\n",
    "xy = pre.preprocessing_model()\n",
    "\n",
    "\n",
    "# Nth preprocessing\n",
    "nth = prenth.PreprocessingNth()\n",
    "\n",
    "# feature_selection\n",
    "fs = nth.feature_selection(*xy)\n",
    "\n",
    "# feature_addition\n",
    "fa = nth.feature_addition(*fs)\n",
    "\n",
    "\n",
    "# Modeling & Result\n",
    "md = mdsc.Modeling(*fa)\n",
    "md.print_score()\n",
    "md.models_score_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
